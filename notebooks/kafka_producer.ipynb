{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import io\n",
    "from confluent_kafka import Producer\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a43d1282443348938af911222743dcef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value=\"\\n        <div style='background: linear-gradient(135deg, #667eea, #764ba2);\\n     ‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dashboard ready! Kafka broker: localhost:9092\n",
      "Available topics: drift_detection_topic\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "import io\n",
    "from confluent_kafka import Producer\n",
    "from confluent_kafka.admin import AdminClient\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def create_producer_config(servers='localhost:9092'):\n",
    "    \"\"\"Configure Kafka producer settings\"\"\"\n",
    "    return {\n",
    "        'bootstrap.servers': servers,\n",
    "        'client.id': 'adaptive-producer'\n",
    "    }\n",
    "\n",
    "def init_kafka_producer(config):\n",
    "    \"\"\"Initialize and return Kafka producer instance\"\"\"\n",
    "    return Producer(config)\n",
    "\n",
    "def load_file_content(file_info):\n",
    "    \"\"\"Extract content from uploaded file\"\"\"\n",
    "    if not file_info:\n",
    "        raise ValueError(\"No file selected\")\n",
    "    return file_info[0]['content'], file_info[0]['name']\n",
    "\n",
    "def parse_csv_data(content):\n",
    "    \"\"\"Parse CSV content into DataFrame\"\"\"\n",
    "    return pd.read_csv(io.BytesIO(content))\n",
    "\n",
    "def parse_arff_data(content):\n",
    "    \"\"\"Parse ARFF content into DataFrame\"\"\"\n",
    "    import arff\n",
    "    if isinstance(content, memoryview):\n",
    "        content = bytes(content)\n",
    "    dataset = arff.loads(content.decode('utf-8'))\n",
    "    df = pd.DataFrame(dataset['data'], columns=[attr[0] for attr in dataset['attributes']])\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "    return df\n",
    "\n",
    "def load_dataset(file_content, filename):\n",
    "    \"\"\"Load dataset based on file extension\"\"\"\n",
    "    if filename.endswith('.csv'):\n",
    "        return parse_csv_data(file_content)\n",
    "    elif filename.endswith('.arff'):\n",
    "        return parse_arff_data(file_content)\n",
    "    raise ValueError(\"Unsupported file format\")\n",
    "\n",
    "def get_numeric_columns(df):\n",
    "    \"\"\"Extract numerical columns from DataFrame\"\"\"\n",
    "    return df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "def get_kafka_topics(servers='localhost:9092'):\n",
    "    \"\"\"Get list of available Kafka topics\"\"\"\n",
    "    try:\n",
    "        admin = AdminClient({'bootstrap.servers': servers})\n",
    "        metadata = admin.list_topics(timeout=5)\n",
    "        return [topic for topic in metadata.topics.keys() if not topic.startswith('__')]\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching topics: {e}\")\n",
    "        return []\n",
    "\n",
    "def create_feature_checkboxes(columns, callback, exclude_cols=None):\n",
    "    \"\"\"Create checkbox widgets for feature selection\"\"\"\n",
    "    exclude_cols = exclude_cols or []\n",
    "    checkboxes = []\n",
    "    for col in columns:\n",
    "        if col not in exclude_cols:\n",
    "            cb = widgets.Checkbox(value=False, description=col)\n",
    "            cb.observe(callback, names='value')\n",
    "            checkboxes.append(cb)\n",
    "    return checkboxes\n",
    "\n",
    "def get_selected_features(checkboxes):\n",
    "    \"\"\"Get list of selected feature names\"\"\"\n",
    "    return [cb.description for cb in checkboxes if cb.value]\n",
    "\n",
    "def prepare_stream_data(df, features, class_col, mapping):\n",
    "    \"\"\"Prepare data for streaming with renamed columns\"\"\"\n",
    "    data = df[features + [class_col]].copy()\n",
    "    data[class_col] = data[class_col].astype(str).map(mapping)\n",
    "\n",
    "    # Dynamic column renaming\n",
    "    col_map = {feat: f'at{i+1}' for i, feat in enumerate(features)}\n",
    "    col_map[class_col] = 'cl'\n",
    "\n",
    "    data = data.rename(columns=col_map)\n",
    "    data['cl'] = data['cl'].astype('category')\n",
    "    return data\n",
    "\n",
    "def send_message(producer, topic, message):\n",
    "    \"\"\"Send single message to Kafka topic\"\"\"\n",
    "    producer.produce(topic, message.encode('utf-8'))\n",
    "    producer.poll(1)\n",
    "\n",
    "def stream_data(producer, topic, data, delay=0.1, check_streaming=None):\n",
    "    \"\"\"Stream data rows to Kafka topic with streaming check\"\"\"\n",
    "    messages = []\n",
    "    for idx, row in data.iterrows():\n",
    "        # Check if streaming should continue\n",
    "        if check_streaming and not check_streaming():\n",
    "            break\n",
    "        msg = row.to_json()\n",
    "        send_message(producer, topic, msg)\n",
    "        messages.append(msg)\n",
    "        yield idx + 1, msg\n",
    "        time.sleep(delay)\n",
    "    producer.flush()\n",
    "\n",
    "class FlexibleKafkaStreamer:\n",
    "    def __init__(self, servers='localhost:9092'):\n",
    "        self.servers = servers\n",
    "        self.topic = None\n",
    "        self.producer = None\n",
    "        self.df = None\n",
    "        self.features = []\n",
    "        self.class_col = None\n",
    "        self.streaming = False\n",
    "        self.count = 0\n",
    "        self.available_topics = []\n",
    "\n",
    "    def build_interface(self):\n",
    "        \"\"\"Build the streaming dashboard interface\"\"\"\n",
    "        # Header\n",
    "        self.header = widgets.HTML(\"\"\"\n",
    "        <div style='background: linear-gradient(135deg, #667eea, #764ba2);\n",
    "                    padding: 20px; border-radius: 10px; color: white; margin-bottom: 20px;'>\n",
    "            <h2 style='margin: 0;'>üöÄ Adaptive Streaming Dashboard</h2>\n",
    "            <p style='margin: 5px 0;'>Flexible Attribute Selection</p>\n",
    "        </div>\n",
    "        \"\"\")\n",
    "\n",
    "        # Topic selection\n",
    "        self.refresh_topics_btn = widgets.Button(\n",
    "            description='üîÑ Refresh Topics',\n",
    "            button_style='info',\n",
    "            layout=widgets.Layout(width='150px')\n",
    "        )\n",
    "        self.topic_selector = widgets.Dropdown(\n",
    "            options=['Select a topic'],\n",
    "            description='Kafka Topic:',\n",
    "            style={'description_width': 'initial'},\n",
    "            layout=widgets.Layout(width='400px')\n",
    "        )\n",
    "\n",
    "        # File section\n",
    "        self.uploader = widgets.FileUpload(accept='.csv,.arff', multiple=False)\n",
    "        self.load_btn = widgets.Button(description='Load Dataset', button_style='primary')\n",
    "        self.status = widgets.Label('Select a dataset file')\n",
    "\n",
    "        # Data preview\n",
    "        self.info_display = widgets.HTML()\n",
    "        self.preview_area = widgets.Output()\n",
    "\n",
    "        # Feature selection\n",
    "        self.feature_box = widgets.VBox()\n",
    "        self.selected_count = widgets.HTML('<b>Selected features: 0</b>')\n",
    "\n",
    "        # Class configuration\n",
    "        self.class_selector = widgets.Dropdown(\n",
    "            options=['Choose class label'],\n",
    "            description='Class Label:',\n",
    "            style={'description_width': 'initial'}\n",
    "        )\n",
    "        self.mapping_box = widgets.VBox()\n",
    "\n",
    "        # Controls\n",
    "        self.start_btn = widgets.Button(\n",
    "            description='‚ñ∂Ô∏è Start Stream',\n",
    "            button_style='success',\n",
    "            disabled=True\n",
    "        )\n",
    "        self.stop_btn = widgets.Button(\n",
    "            description='‚èπÔ∏è Stop',\n",
    "            button_style='danger',\n",
    "            disabled=True\n",
    "        )\n",
    "\n",
    "        # Statistics\n",
    "        self.progress = widgets.IntProgress(\n",
    "            description='Progress:',\n",
    "            bar_style='info'\n",
    "        )\n",
    "        self.log_display = widgets.Textarea(\n",
    "            placeholder='Streaming log...',\n",
    "            disabled=True,\n",
    "            layout=widgets.Layout(width='100%', height='120px')\n",
    "        )\n",
    "\n",
    "        # Connect handlers\n",
    "        self.refresh_topics_btn.on_click(self._refresh_topics)\n",
    "        self.topic_selector.observe(self._handle_topic_change, 'value')\n",
    "        self.load_btn.on_click(self._handle_load)\n",
    "        self.class_selector.observe(self._handle_class_change, 'value')\n",
    "        self.start_btn.on_click(self._handle_start)\n",
    "        self.stop_btn.on_click(self._handle_stop)\n",
    "\n",
    "        # Load topics on init\n",
    "        self._refresh_topics(None)\n",
    "\n",
    "        # Layout assembly\n",
    "        return widgets.VBox([\n",
    "            self.header,\n",
    "            widgets.VBox([\n",
    "                widgets.HTML('<h3>üéØ Kafka Topic Selection</h3>'),\n",
    "                widgets.HBox([self.topic_selector, self.refresh_topics_btn])\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                widgets.HTML('<h3>üìÅ Dataset Input</h3>'),\n",
    "                widgets.HBox([self.uploader, self.load_btn]),\n",
    "                self.status\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                widgets.HTML('<h3>üìä Data Preview</h3>'),\n",
    "                self.info_display,\n",
    "                self.preview_area\n",
    "            ]),\n",
    "            widgets.VBox([\n",
    "                widgets.HTML('<h3>‚öôÔ∏è Stream Configuration</h3>'),\n",
    "                widgets.HTML('<b>Select Features (any number):</b>'),\n",
    "                self.selected_count,\n",
    "                self.feature_box,\n",
    "                widgets.HTML('<br>'),\n",
    "                self.class_selector,\n",
    "                widgets.HTML('<b>Class Value Mapping:</b>'),\n",
    "                self.mapping_box\n",
    "            ]),\n",
    "            widgets.HBox([self.start_btn, self.stop_btn]),\n",
    "            widgets.VBox([\n",
    "                widgets.HTML('<h3>üìà Stream Status</h3>'),\n",
    "                self.progress,\n",
    "                self.log_display\n",
    "            ])\n",
    "        ], layout=widgets.Layout(padding='10px'))\n",
    "\n",
    "    def _handle_load(self, _):\n",
    "        \"\"\"Handle dataset loading\"\"\"\n",
    "        self.status.value = 'Loading...'\n",
    "        try:\n",
    "            content, name = load_file_content(self.uploader.value)\n",
    "            self.df = load_dataset(content, name)\n",
    "            self.status.value = f'Loaded: {name} ({len(self.df)} rows)'\n",
    "            self._show_preview()\n",
    "            self._setup_features()\n",
    "        except Exception as e:\n",
    "            self.status.value = f'Error: {str(e)}'\n",
    "\n",
    "    def _show_preview(self):\n",
    "        \"\"\"Display dataset information\"\"\"\n",
    "        self.info_display.value = f\"\"\"\n",
    "        <p><b>Shape:</b> {self.df.shape[0]} √ó {self.df.shape[1]}</p>\n",
    "        <p><b>Columns:</b> {', '.join(list(self.df.columns)[:5])}{'...' if len(self.df.columns) > 5 else ''}</p>\n",
    "        \"\"\"\n",
    "        with self.preview_area:\n",
    "            clear_output()\n",
    "            display(self.df.head())\n",
    "\n",
    "    def _refresh_topics(self, _):\n",
    "        \"\"\"Refresh available Kafka topics\"\"\"\n",
    "        self.available_topics = get_kafka_topics(self.servers)\n",
    "        if self.available_topics:\n",
    "            self.topic_selector.options = ['Select a topic'] + self.available_topics\n",
    "            self.status.value = f'Found {len(self.available_topics)} topics'\n",
    "        else:\n",
    "            self.topic_selector.options = ['No topics found']\n",
    "            self.status.value = 'No topics found. Create a topic first.'\n",
    "\n",
    "    def _handle_topic_change(self, change):\n",
    "        \"\"\"Handle topic selection\"\"\"\n",
    "        if change['new'] not in ['Select a topic', 'No topics found']:\n",
    "            self.topic = change['new']\n",
    "            self._check_ready()\n",
    "\n",
    "    def _setup_features(self):\n",
    "        \"\"\"Setup feature selection interface\"\"\"\n",
    "        numeric_cols = get_numeric_columns(self.df)\n",
    "        if not numeric_cols:\n",
    "            self.status.value = 'No numerical features found!'\n",
    "            return\n",
    "\n",
    "        # Exclude potential class columns (cl, class, target, etc.)\n",
    "        exclude_patterns = ['cl', 'class', 'target', 'label']\n",
    "        exclude_cols = [col for col in numeric_cols\n",
    "                       if any(pattern in col.lower() for pattern in exclude_patterns)]\n",
    "\n",
    "        self.checkboxes = create_feature_checkboxes(numeric_cols, self._update_features, exclude_cols)\n",
    "        self.feature_box.children = self.checkboxes\n",
    "        self.class_selector.options = ['Choose class label'] + list(self.df.columns)\n",
    "\n",
    "    def _update_features(self, _):\n",
    "        \"\"\"Update selected features\"\"\"\n",
    "        self.features = get_selected_features(self.checkboxes)\n",
    "        self.selected_count.value = f'<b>Selected features: {len(self.features)}</b>'\n",
    "        self._check_ready()\n",
    "\n",
    "    def _handle_class_change(self, change):\n",
    "        \"\"\"Handle class selection\"\"\"\n",
    "        if change['new'] != 'Choose class label':\n",
    "            self.class_col = change['new']\n",
    "            self._setup_mapping()\n",
    "        else:\n",
    "            self.class_col = None\n",
    "            self.mapping_box.children = []\n",
    "        self._check_ready()\n",
    "\n",
    "    def _setup_mapping(self):\n",
    "        \"\"\"Setup class value mapping interface\"\"\"\n",
    "        unique_vals = self.df[self.class_col].unique()\n",
    "        self.mapping_inputs = {}\n",
    "\n",
    "        widgets_list = []\n",
    "        for i, val in enumerate(unique_vals):\n",
    "            text_input = widgets.IntText(value=i, layout=widgets.Layout(width='80px'))\n",
    "            self.mapping_inputs[str(val)] = text_input\n",
    "            widgets_list.append(widgets.HBox([\n",
    "                widgets.Label(f'{val} ‚Üí'),\n",
    "                text_input\n",
    "            ]))\n",
    "\n",
    "        self.mapping_box.children = widgets_list\n",
    "\n",
    "    def _check_ready(self):\n",
    "        \"\"\"Check if configuration is complete\"\"\"\n",
    "        self.start_btn.disabled = not (self.features and self.class_col and\n",
    "                                      self.class_col != 'Choose class label' and\n",
    "                                      self.topic and self.topic != 'Select a topic')\n",
    "\n",
    "    def _handle_start(self, _):\n",
    "        \"\"\"Start streaming process\"\"\"\n",
    "        try:\n",
    "            # Get mappings\n",
    "            mapping = {k: v.value for k, v in self.mapping_inputs.items()}\n",
    "\n",
    "            # Initialize producer\n",
    "            if not self.producer:\n",
    "                config = create_producer_config(self.servers)\n",
    "                self.producer = init_kafka_producer(config)\n",
    "                print(f\"Producer initialized for topic: {self.topic}\")\n",
    "\n",
    "            self.streaming = True\n",
    "            self.count = 0\n",
    "\n",
    "            # Update UI\n",
    "            self.start_btn.disabled = True\n",
    "            self.stop_btn.disabled = False\n",
    "            self.status.value = 'Streaming...'\n",
    "            self.log_display.value = ''\n",
    "\n",
    "            # Prepare data\n",
    "            stream_df = prepare_stream_data(self.df, self.features, self.class_col, mapping)\n",
    "            self.progress.max = len(stream_df)\n",
    "            self.progress.value = 0\n",
    "\n",
    "            # Stream messages with streaming check\n",
    "            for count, msg in stream_data(self.producer, self.topic, stream_df,\n",
    "                                         check_streaming=lambda: self.streaming):\n",
    "                if not self.streaming:\n",
    "                    break\n",
    "\n",
    "                self.count = count\n",
    "                self.progress.value = count\n",
    "\n",
    "                if count <= 5:\n",
    "                    self.log_display.value += f\"[{count}] {msg}\\n\"\n",
    "\n",
    "            # Only call stop if streaming completed naturally\n",
    "            if self.streaming:\n",
    "                self._handle_stop(None)\n",
    "\n",
    "        except Exception as e:\n",
    "            self.status.value = f'Error: {str(e)}'\n",
    "            self._handle_stop(None)\n",
    "\n",
    "    def _handle_stop(self, _):\n",
    "        \"\"\"Stop streaming process\"\"\"\n",
    "        self.streaming = False\n",
    "        self.start_btn.disabled = False\n",
    "        self.stop_btn.disabled = True\n",
    "        if self.count > 0:\n",
    "            self.status.value = f'Streamed {self.count} messages to {self.topic}'\n",
    "        else:\n",
    "            self.status.value = 'Streaming stopped'\n",
    "\n",
    "    def launch(self):\n",
    "        \"\"\"Launch the streaming dashboard\"\"\"\n",
    "        dashboard = self.build_interface()\n",
    "        display(dashboard)\n",
    "        print(f\"Dashboard ready! Kafka broker: {self.servers}\")\n",
    "        if self.available_topics:\n",
    "            print(f\"Available topics: {', '.join(self.available_topics)}\")\n",
    "        else:\n",
    "            print(\"No topics found. Create a topic using:\")\n",
    "            print(\"bin/kafka-topics.sh --create --topic your_topic --bootstrap-server localhost:9092\")\n",
    "\n",
    "# Initialize and launch the streamer\n",
    "streamer = FlexibleKafkaStreamer()\n",
    "streamer.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "concept_drift_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
